{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b735b9f5-391b-4db8-984d-2bb3a296309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zad11 import connect, load_table, process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1a9c494-e6a1-4ffa-afc2-2bbc4166600c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Spark...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/10 17:16:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/10 17:16:26 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://jupyter-lab:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Zad11</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x76d475f55650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark = connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8cf67e1-f514-4b36-a02b-09dec420d0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading '/input/daily_weather_2017.csv' into table 'daily_weather_2017'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[station_id: string, date: string, avg_temp_c: string, precipitation_mm: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_table(spark, \"/input/daily_weather_2017.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c05a48d-b0a0-48cf-b4f4-dcbeca8b2ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading '/input/cities.csv' into table 'cities'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[station_id: string, city_name: string, country: string, state: string, iso2: string, iso3: string, latitude: string, longitude: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_table(spark, \"/input/cities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "569fec65-9ecc-449d-a920-473ebff5770e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing query and saving to '/daily_country_weather/*'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 5.779 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------------+----------------+\n",
      "|    country|      date|       temperature_c|precipitation_mm|\n",
      "+-----------+----------+--------------------+----------------+\n",
      "|Afghanistan|2017-01-01|  5.3166666666666655|             0.0|\n",
      "|Afghanistan|2017-01-02|   5.016666666666667|             2.0|\n",
      "|Afghanistan|2017-01-03|  3.0666666666666664|          10.725|\n",
      "|Afghanistan|2017-01-04|                2.65|           109.0|\n",
      "|Afghanistan|2017-01-05|  1.9333333333333333|           29.95|\n",
      "|Afghanistan|2017-01-06|  0.9833333333333331|            7.25|\n",
      "|Afghanistan|2017-01-07| 0.28333333333333344|            33.0|\n",
      "|Afghanistan|2017-01-08|-0.07999999999999999|            18.0|\n",
      "|Afghanistan|2017-01-09|-0.21666666666666676|             0.0|\n",
      "|Afghanistan|2017-01-10|   0.866666666666667|             0.0|\n",
      "|Afghanistan|2017-01-11|  0.4499999999999999|             0.0|\n",
      "|Afghanistan|2017-01-12|  -0.616666666666667|             0.0|\n",
      "|Afghanistan|2017-01-13| -0.8399999999999999|             0.0|\n",
      "|Afghanistan|2017-01-14| -0.7500000000000001|             9.9|\n",
      "|Afghanistan|2017-01-15| -2.1333333333333333|             3.8|\n",
      "|Afghanistan|2017-01-16| -0.5166666666666665|             0.0|\n",
      "|Afghanistan|2017-01-17|-0.06666666666666672|            18.0|\n",
      "|Afghanistan|2017-01-18|-0.11666666666666654|             1.0|\n",
      "|Afghanistan|2017-01-19|  2.6333333333333333|           29.95|\n",
      "|Afghanistan|2017-01-20|  2.1999999999999997|             0.0|\n",
      "+-----------+----------+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "process(spark, \"daily_country_weather\", \"\"\"\n",
    "SELECT\n",
    "    c.country,\n",
    "    w.date,\n",
    "    AVG(w.temperature_c) as temperature_c,\n",
    "    COALESCE(AVG(w.precipitation_mm), 0) as precipitation_mm\n",
    "FROM (\n",
    "    SELECT\n",
    "        station_id,\n",
    "        to_date(date) as date,\n",
    "        avg_temp_c as temperature_c,\n",
    "        precipitation_mm\n",
    "    FROM daily_weather_2017\n",
    "    WHERE date BETWEEN '2017-01-01' AND '2021-12-31'\n",
    ") AS w\n",
    "JOIN cities AS c\n",
    "    ON w.station_id = c.station_id\n",
    "GROUP BY c.country, w.date\n",
    "HAVING temperature_c IS NOT NULL\n",
    "ORDER BY c.country, w.date\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0f9d670-7be2-4d94-b13c-190207f840e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
